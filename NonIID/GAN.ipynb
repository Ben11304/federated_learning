{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_work import processed\n",
    "df=pd.read_csv(\"/Users/mac/Dev/data/dta_IoT/new2test.csv\")\n",
    "#delete all null columns\n",
    "id=[16,17,21,22,23,24]\n",
    "col=df.columns\n",
    "for idx in id:\n",
    "    df=df.drop(col[idx],axis=1)\n",
    "data=processed(df,\"subcategory \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subcategory</th>\n",
       "      <th>pkSeqID</th>\n",
       "      <th>stime</th>\n",
       "      <th>flgs</th>\n",
       "      <th>proto</th>\n",
       "      <th>saddr</th>\n",
       "      <th>sport</th>\n",
       "      <th>daddr</th>\n",
       "      <th>dport</th>\n",
       "      <th>pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>max</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>srate</th>\n",
       "      <th>drate</th>\n",
       "      <th>attack</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5425</td>\n",
       "      <td>2934</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>20</td>\n",
       "      <td>901</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1253</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "      <td>108</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3463</td>\n",
       "      <td>6036</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2366</td>\n",
       "      <td>24</td>\n",
       "      <td>609</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>582</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>507</td>\n",
       "      <td>32</td>\n",
       "      <td>2124</td>\n",
       "      <td>1589</td>\n",
       "      <td>1334</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1890</td>\n",
       "      <td>1801</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>996</td>\n",
       "      <td>26</td>\n",
       "      <td>697</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>6078</td>\n",
       "      <td>3586</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>356</td>\n",
       "      <td>25</td>\n",
       "      <td>901</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2029</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>552</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1244</td>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4755</td>\n",
       "      <td>3</td>\n",
       "      <td>970</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>2545</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>535</td>\n",
       "      <td>173</td>\n",
       "      <td>1315</td>\n",
       "      <td>1214</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>3</td>\n",
       "      <td>1304</td>\n",
       "      <td>1215</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>770</td>\n",
       "      <td>27</td>\n",
       "      <td>697</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>555</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>2</td>\n",
       "      <td>3436</td>\n",
       "      <td>6010</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1493</td>\n",
       "      <td>24</td>\n",
       "      <td>210</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>2421</td>\n",
       "      <td>1685</td>\n",
       "      <td>1420</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>1</td>\n",
       "      <td>4747</td>\n",
       "      <td>5103</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3979</td>\n",
       "      <td>20</td>\n",
       "      <td>900</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>253</td>\n",
       "      <td>81</td>\n",
       "      <td>632</td>\n",
       "      <td>446</td>\n",
       "      <td>504</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>7</td>\n",
       "      <td>6090</td>\n",
       "      <td>3598</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "      <td>25</td>\n",
       "      <td>901</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2029</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>368</td>\n",
       "      <td>552</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>6</td>\n",
       "      <td>5356</td>\n",
       "      <td>2865</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>20</td>\n",
       "      <td>901</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>1161</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>12</td>\n",
       "      <td>109</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7026 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subcategory   pkSeqID  stime  flgs  proto  saddr  sport  daddr  dport  \\\n",
       "0                6     5425   2934     6      2      0    184     20    901   \n",
       "1                2     3463   6036     0      2      2   2366     24    609   \n",
       "2                3     1890   1801     0      3     11    996     26    697   \n",
       "3                7     6078   3586     0      3      0    356     25    901   \n",
       "4                3     1244   1162     0      2      5   4755      3    970   \n",
       "...            ...      ...    ...   ...    ...    ...    ...    ...    ...   \n",
       "7021             3     1304   1215     0      3      2    770     27    697   \n",
       "7022             2     3436   6010     0      2      2   1493     24    210   \n",
       "7023             1     4747   5103     0      2      2   3979     20    900   \n",
       "7024             7     6090   3598     0      3      0    370     25    901   \n",
       "7025             6     5356   2865     6      2      0    172     20    901   \n",
       "\n",
       "      pkts  ...   max  spkts  dpkts  sbytes  dbytes  rate  srate  drate  \\\n",
       "0        8  ...  1253      5      3      86      12   108     31     15   \n",
       "1        9  ...   582      5      4     507      32  2124   1589   1334   \n",
       "2        1  ...     0      1      0      41       0   112    276      0   \n",
       "3        9  ...  2029      9      0      71       0   368    552      0   \n",
       "4       57  ...  2545     42     42     535     173  1315   1214   1003   \n",
       "...    ...  ...   ...    ...    ...     ...     ...   ...    ...    ...   \n",
       "7021     1  ...     0      1      0      41       0   555    740      0   \n",
       "7022     9  ...   298      5      4      64      54  2421   1685   1420   \n",
       "7023     9  ...   258      5      4     253      81   632    446    504   \n",
       "7024     9  ...  2029      9      0      71       0   368    552      0   \n",
       "7025     8  ...  1161      5      3      86      12   109     32     17   \n",
       "\n",
       "      attack  category  \n",
       "0          1         0  \n",
       "1          1         3  \n",
       "2          0         1  \n",
       "3          1         0  \n",
       "4          0         1  \n",
       "...      ...       ...  \n",
       "7021       0         1  \n",
       "7022       1         3  \n",
       "7023       1         0  \n",
       "7024       1         0  \n",
       "7025       1         0  \n",
       "\n",
       "[7026 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        [0, 0, 0,  ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "labels=torch.tensor(data[\"subcategory \"])\n",
    "labels_one_hot = F.one_hot(labels, 8)\n",
    "labels_one_hot \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 114 samples\n",
      "Label 1: 994 samples\n",
      "Label 2: 995 samples\n",
      "Label 3: 931 samples\n",
      "Label 4: 992 samples\n",
      "Label 5: 1000 samples\n",
      "Label 6: 1000 samples\n",
      "Label 7: 1000 samples\n"
     ]
    }
   ],
   "source": [
    "label_counts = torch.sum(labels_one_hot, dim=0)\n",
    "num_labels = label_counts.size(0)\n",
    "for label_idx in range(num_labels):\n",
    "    label_count = label_counts[label_idx].item()\n",
    "    print(f\"Label {label_idx}: {label_count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"subcategory \",axis=1)\n",
    "X=torch.tensor(X.values)\n",
    "data=torch.cat((X, labels_one_hot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, torch, time, os, pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class generator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=32, class_num=8):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim + self.class_num, 64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128 ,self.output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32, class_num=8):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim + self.class_num, 64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128 ,self.output_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CGAN(object):\n",
    "    def __init__(self, args):\n",
    "        # parameters\n",
    "        self.epoch = args.epoch\n",
    "        self.batch_size = args.batch_size\n",
    "        self.save_dir = args.save_dir\n",
    "        self.result_dir = args.result_dir\n",
    "        self.dataset = args.dataset\n",
    "        self.log_dir = args.log_dir\n",
    "        self.gpu_mode = args.gpu_mode\n",
    "        self.model_name = args.gan_type\n",
    "        self.input_size = args.input_size\n",
    "        self.z_dim = args.z_dim\n",
    "        self.class_num = args.n_class\n",
    "        self.sample_num = self.class_num ** 2 \n",
    "        # load dataset\n",
    "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        data=next(iter(self.data_loader))\n",
    "        #option\n",
    "        dim=int(data.shape[1])-8\n",
    "\n",
    "        # networks init\n",
    "        self.G = generator(input_dim=self.z_dim, output_dim=dim, input_size=self.input_size, class_num=self.class_num)\n",
    "        self.D = discriminator(input_dim=dim, output_dim=1, input_size=self.input_size, class_num=self.class_num)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG)\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD)\n",
    "        \n",
    "        self.BCE_loss = nn.BCELoss()\n",
    "\n",
    "        print('---------- Networks architecture -------------')\n",
    "        utils.print_network(self.G)\n",
    "        utils.print_network(self.D)\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "\n",
    "        # fixed noise & condition\n",
    "        self.sample_z_ = torch.zeros((self.sample_num, self.z_dim)) # z_dim tượng trưng cho noise vector, vector nhiều có kích thuóc dài bằng vector onehotencoded^2 của label \n",
    "        for i in range(self.class_num):\n",
    "            self.sample_z_[i*self.class_num] = torch.rand(1, self.z_dim)#tạo một vector random có kích thuớc 1, z_dim ( chiều dài của vector nhiễu )\n",
    "            for j in range(1, self.class_num):\n",
    "                self.sample_z_[i*self.class_num + j] = self.sample_z_[i*self.class_num]\n",
    "\n",
    "        temp = torch.zeros((self.class_num, 1))\n",
    "        for i in range(self.class_num):\n",
    "            temp[i, 0] = i\n",
    "\n",
    "        temp_y = torch.zeros((self.sample_num, 1))\n",
    "        for i in range(self.class_num):\n",
    "            temp_y[i*self.class_num: (i+1)*self.class_num] = temp\n",
    "\n",
    "        self.sample_y_ = torch.zeros((self.sample_num, self.class_num)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['per_epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "\n",
    "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n",
    "\n",
    "        self.D.train()\n",
    "        print('training start!!')\n",
    "        start_time = time.time()\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train()\n",
    "            epoch_start_time = time.time()\n",
    "            for iter, da in enumerate(self.data_loader):\n",
    "                x_=da[:,:28].float()\n",
    "                y_=da[:,-8:].float()\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                # update D network\n",
    "                self.D.train()\n",
    "                self.G.eval()\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_, y_)\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "                G_ = self.G(z_, y_)\n",
    "                D_fake = self.D(G_, y_)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                 # update G network\n",
    "                self.D.eval()\n",
    "                self.G.train()\n",
    "                self.G_optimizer.zero_grad()\n",
    "\n",
    "                z_=torch.rand((self.batch_size, self.z_dim))\n",
    "                y = torch.randint(low=0, high=8, size=(self.batch_size,))\n",
    "                y_label_ = F.one_hot(y, 8)\n",
    "                G_ = self.G(z_, y_label_)\n",
    "                D_fake = self.D(G_, y_label_)\n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "               \n",
    "                if ((iter + 1) % 100) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
    "\n",
    "            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
    "                \n",
    "\n",
    "        self.train_hist['total_time'].append(time.time() - start_time)\n",
    "        print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.train_hist['per_epoch_time']),\n",
    "              self.epoch, self.train_hist['total_time'][0]))\n",
    "        print(\"Training finish!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self,data):\n",
    "        self.epoch = 10\n",
    "        self.batch_size = 32\n",
    "        self.save_dir = '/Users/mac/Dev/source/article/FerderatedLearning/federated_learning/NonIID/model.h5'\n",
    "        self.result_dir = '/Users/mac/Dev/source/article/FerderatedLearning/federated_learning/NonIID/result.txt'\n",
    "        self.dataset = data\n",
    "        self.log_dir = 'logs/'\n",
    "        self.gpu_mode = True\n",
    "        self.gan_type = 'cGAN'\n",
    "        self.input_size = 3200\n",
    "        self.z_dim = 2\n",
    "        self.n_class = 8\n",
    "        self.sample_num = self.n_class ** 2\n",
    "        self.lrG=0.0001\n",
    "        self.lrD=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5425, 2934,    6,  ...,    0,    1,    0],\n",
      "        [3463, 6036,    0,  ...,    0,    0,    0],\n",
      "        [1890, 1801,    0,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [4747, 5103,    0,  ...,    0,    0,    0],\n",
      "        [6090, 3598,    0,  ...,    0,    0,    1],\n",
      "        [5356, 2865,    6,  ...,    0,    1,    0]])\n"
     ]
    }
   ],
   "source": [
    "arg=Args(data)\n",
    "print(arg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=128, out_features=28, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 12892\n",
      "discriminator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=36, out_features=64, bias=True)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (6): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 10817\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model=CGAN(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!!\n",
      "Epoch: [ 1] [ 100/ 219] D_loss: 0.68373287, G_loss: 0.70363426\n",
      "Epoch: [ 1] [ 200/ 219] D_loss: 0.67075890, G_loss: 0.71750754\n",
      "Epoch: [ 2] [ 100/ 219] D_loss: 0.63447922, G_loss: 0.75497872\n",
      "Epoch: [ 2] [ 200/ 219] D_loss: 0.57962519, G_loss: 0.82375431\n",
      "Epoch: [ 3] [ 100/ 219] D_loss: 0.50504225, G_loss: 0.92836130\n",
      "Epoch: [ 3] [ 200/ 219] D_loss: 0.39176321, G_loss: 1.13723028\n",
      "Epoch: [ 4] [ 100/ 219] D_loss: 0.27487636, G_loss: 1.39896297\n",
      "Epoch: [ 4] [ 200/ 219] D_loss: 0.21980664, G_loss: 1.66701269\n",
      "Epoch: [ 5] [ 100/ 219] D_loss: 0.13627894, G_loss: 2.08880162\n",
      "Epoch: [ 5] [ 200/ 219] D_loss: 0.12185574, G_loss: 2.18447304\n",
      "Epoch: [ 6] [ 100/ 219] D_loss: 0.07491970, G_loss: 2.62214351\n",
      "Epoch: [ 6] [ 200/ 219] D_loss: 0.05226010, G_loss: 2.88647676\n",
      "Epoch: [ 7] [ 100/ 219] D_loss: 0.04796908, G_loss: 3.04335070\n",
      "Epoch: [ 7] [ 200/ 219] D_loss: 0.03701843, G_loss: 3.40809345\n",
      "Epoch: [ 8] [ 100/ 219] D_loss: 0.02085172, G_loss: 3.81437182\n",
      "Epoch: [ 8] [ 200/ 219] D_loss: 0.01869967, G_loss: 4.00096130\n",
      "Epoch: [ 9] [ 100/ 219] D_loss: 0.01851646, G_loss: 3.93355489\n",
      "Epoch: [ 9] [ 200/ 219] D_loss: 0.01487092, G_loss: 4.35595226\n",
      "Epoch: [10] [ 100/ 219] D_loss: 0.00884672, G_loss: 4.64153004\n",
      "Epoch: [10] [ 200/ 219] D_loss: 0.00910711, G_loss: 4.70196867\n",
      "Avg one epoch time: 0.51, total 10 epochs time: 5.06\n",
      "Training finish!\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor([1,2,3,4,5,6,7,0,1,2,3,4,5,6,7,0,1,2,3,4,5,6,7,0])\n",
    "y=F.one_hot(y, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len=y.shape[0]\n",
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/2h4f0bj12r775fg_s2v4hpqh0000gn/T/ipykernel_40440/949614172.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y=torch.tensor(y)\n"
     ]
    }
   ],
   "source": [
    "z= torch.rand(len,2)\n",
    "y=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1450, 0.2414],\n",
       "        [0.6399, 0.0262],\n",
       "        [0.4495, 0.3421],\n",
       "        [0.6839, 0.8740],\n",
       "        [0.8144, 0.7765],\n",
       "        [0.4800, 0.0614],\n",
       "        [0.8289, 0.0341],\n",
       "        [0.2718, 0.7847],\n",
       "        [0.4388, 0.6797],\n",
       "        [0.1786, 0.4666],\n",
       "        [0.7619, 0.8936],\n",
       "        [0.4904, 0.3848],\n",
       "        [0.5010, 0.0805],\n",
       "        [0.8361, 0.0950],\n",
       "        [0.2121, 0.3462],\n",
       "        [0.3835, 0.8032],\n",
       "        [0.8578, 0.8176],\n",
       "        [0.5582, 0.2958],\n",
       "        [0.0874, 0.1209],\n",
       "        [0.6398, 0.9048],\n",
       "        [0.2104, 0.7998],\n",
       "        [0.5815, 0.7665],\n",
       "        [0.5457, 0.7531],\n",
       "        [0.0763, 0.6362]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=torch.cat([z,y],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1450, 0.2414, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.6399, 0.0262, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.4495, 0.3421, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.6839, 0.8740, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.8144, 0.7765, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.4800, 0.0614, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000],\n",
       "        [0.8289, 0.0341, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.0000],\n",
       "        [0.2718, 0.7847, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.4388, 0.6797, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.1786, 0.4666, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.7619, 0.8936, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.4904, 0.3848, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.5010, 0.0805, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.8361, 0.0950, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000],\n",
       "        [0.2121, 0.3462, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.0000],\n",
       "        [0.3835, 0.8032, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.8578, 0.8176, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.5582, 0.2958, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0874, 0.1209, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.6398, 0.9048, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.2104, 0.7998, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.5815, 0.7665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000,\n",
       "         0.0000],\n",
       "        [0.5457, 0.7531, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.0000],\n",
       "        [0.0763, 0.6362, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake=model.G(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9999, -0.9575,  0.6972,  0.7160, -0.7945,  0.9942,  0.7253,  0.9391,\n",
       "         -0.6657,  0.1152,  0.4850,  1.0000,  0.9478,  0.9998,  0.9628,  0.8351,\n",
       "          0.7791,  0.5601,  0.9918,  0.7914,  0.6807,  0.4362,  0.8381,  0.9571,\n",
       "          0.8996,  0.7545,  0.7566, -0.8052],\n",
       "        [ 0.9999, -0.9332,  0.8042,  0.6415, -0.7754,  0.9964,  0.6721,  0.8414,\n",
       "         -0.5784,  0.6009,  0.1727,  0.9999,  0.9646,  0.9991,  0.9712,  0.8309,\n",
       "          0.9155, -0.0598,  0.9675,  0.7141,  0.6152,  0.7843,  0.8892,  0.9812,\n",
       "          0.9601,  0.8216,  0.7857, -0.8310],\n",
       "        [ 0.9999, -0.9687,  0.6014,  0.6075, -0.7544,  0.9892,  0.7818,  0.9737,\n",
       "         -0.5874, -0.1260,  0.6106,  1.0000,  0.9644,  0.9997,  0.9706,  0.7597,\n",
       "          0.7117,  0.4759,  0.9913,  0.7541,  0.6196,  0.4679,  0.8173,  0.9412,\n",
       "          0.8636,  0.7715,  0.6307, -0.7390],\n",
       "        [ 1.0000, -0.9832,  0.6649,  0.6699, -0.8105,  0.9951,  0.8373,  0.9865,\n",
       "         -0.6510, -0.1503,  0.6738,  1.0000,  0.9805,  0.9999,  0.9844,  0.8158,\n",
       "          0.7729,  0.5338,  0.9961,  0.8107,  0.6815,  0.5294,  0.8678,  0.9654,\n",
       "          0.9072,  0.8283,  0.6931, -0.7969],\n",
       "        [ 1.0000, -0.9866,  0.7626,  0.7763, -0.8636,  0.9983,  0.8450,  0.9843,\n",
       "         -0.7451,  0.0131,  0.6387,  1.0000,  0.9833,  1.0000,  0.9885,  0.8886,\n",
       "          0.8485,  0.6293,  0.9980,  0.8631,  0.7592,  0.5527,  0.9057,  0.9819,\n",
       "          0.9458,  0.8515,  0.8089, -0.8685],\n",
       "        [ 0.9999, -0.9494,  0.7857,  0.5927, -0.7655,  0.9965,  0.6419,  0.7958,\n",
       "         -0.5387,  0.5322,  0.2679,  0.9999,  0.9686,  0.9994,  0.9632,  0.7922,\n",
       "          0.8841, -0.1912,  0.9741,  0.7283,  0.6459,  0.7667,  0.8785,  0.9782,\n",
       "          0.9445,  0.8018,  0.7538, -0.8329],\n",
       "        [ 1.0000, -0.9827,  0.9251,  0.8081, -0.9041,  0.9998,  0.8305,  0.9476,\n",
       "         -0.7501,  0.7716,  0.2122,  1.0000,  0.9937,  1.0000,  0.9958,  0.9407,\n",
       "          0.9804, -0.0500,  0.9941,  0.8568,  0.7667,  0.9139,  0.9682,  0.9978,\n",
       "          0.9937,  0.9358,  0.9135, -0.9372],\n",
       "        [ 0.9986, -0.8586,  0.1385,  0.0357, -0.5301,  0.7959, -0.1856, -0.3014,\n",
       "          0.0784, -0.2799,  0.5763,  0.9992,  0.7619,  0.9953, -0.2758, -0.1403,\n",
       "         -0.5361, -0.2927,  0.9551,  0.6770,  0.4933, -0.3748,  0.2849,  0.1416,\n",
       "         -0.3828,  0.4019,  0.0770, -0.5392],\n",
       "        [ 1.0000, -0.9793,  0.2021, -0.2193, -0.5382,  0.9283, -0.1741, -0.1120,\n",
       "          0.1769, -0.6265,  0.8120,  1.0000,  0.9662,  0.9997, -0.2153, -0.4303,\n",
       "         -0.7523, -0.7378,  0.9917,  0.7300,  0.5082, -0.0576,  0.5085,  0.4335,\n",
       "         -0.5473,  0.5002, -0.2087, -0.5316],\n",
       "        [ 0.9999, -0.9365,  0.8165,  0.6582, -0.7875,  0.9970,  0.6870,  0.8555,\n",
       "         -0.5943,  0.6182,  0.1651,  0.9999,  0.9678,  0.9992,  0.9748,  0.8439,\n",
       "          0.9247, -0.0452,  0.9699,  0.7235,  0.6212,  0.7973,  0.8979,  0.9836,\n",
       "          0.9653,  0.8340,  0.7988, -0.8396],\n",
       "        [ 1.0000, -0.9915,  0.5508,  0.5201, -0.7862,  0.9905,  0.8888,  0.9967,\n",
       "         -0.5267, -0.4690,  0.8120,  1.0000,  0.9911,  0.9999,  0.9905,  0.7019,\n",
       "          0.6791,  0.4113,  0.9969,  0.7738,  0.5966,  0.6053,  0.8598,  0.9572,\n",
       "          0.8693,  0.8716,  0.4972, -0.6994],\n",
       "        [ 0.9999, -0.9570,  0.6965,  0.7154, -0.7938,  0.9941,  0.7239,  0.9384,\n",
       "         -0.6648,  0.1159,  0.4836,  1.0000,  0.9473,  0.9998,  0.9624,  0.8346,\n",
       "          0.7783,  0.5595,  0.9917,  0.7906,  0.6798,  0.4351,  0.8373,  0.9568,\n",
       "          0.8990,  0.7536,  0.7561, -0.8044],\n",
       "        [ 0.9999, -0.9458,  0.6817,  0.7001, -0.7773,  0.9923,  0.6901,  0.9198,\n",
       "         -0.6429,  0.1318,  0.4494,  0.9999,  0.9340,  0.9996,  0.9521,  0.8205,\n",
       "          0.7590,  0.5444,  0.9891,  0.7732,  0.6596,  0.4078,  0.8191,  0.9482,\n",
       "          0.8851,  0.7306,  0.7419, -0.7870],\n",
       "        [ 0.9998, -0.9526,  0.0211, -0.2075, -0.5408,  0.7970, -0.3161, -0.3614,\n",
       "          0.2710, -0.5731,  0.7710,  0.9999,  0.8999,  0.9990, -0.5070, -0.4816,\n",
       "         -0.8074, -0.6051,  0.9843,  0.7080,  0.4890, -0.3983,  0.2688, -0.0191,\n",
       "         -0.7075,  0.4163, -0.1976, -0.4935],\n",
       "        [ 1.0000, -0.9400,  0.8803,  0.7429, -0.8499,  0.9985,  0.7720,  0.9324,\n",
       "         -0.6793,  0.7320,  0.0673,  0.9999,  0.9795,  0.9995,  0.9888,  0.9067,\n",
       "          0.9651,  0.1589,  0.9752,  0.7474,  0.6191,  0.8589,  0.9348,  0.9919,\n",
       "          0.9856,  0.8919,  0.8606, -0.8684],\n",
       "        [ 0.9983, -0.8392,  0.1755,  0.0814, -0.5330,  0.8086, -0.1629, -0.2753,\n",
       "          0.0328, -0.2318,  0.5373,  0.9990,  0.7448,  0.9945, -0.2275, -0.0713,\n",
       "         -0.4712, -0.2328,  0.9503,  0.6713,  0.4868, -0.3508,  0.3079,  0.1968,\n",
       "         -0.3025,  0.4022,  0.1218, -0.5440],\n",
       "        [ 1.0000, -0.9932,  0.6255,  0.6084, -0.8248,  0.9953,  0.8995,  0.9969,\n",
       "         -0.6095, -0.4025,  0.8060,  1.0000,  0.9926,  1.0000,  0.9929,  0.7796,\n",
       "          0.7508,  0.4865,  0.9981,  0.8192,  0.6632,  0.6185,  0.8887,  0.9714,\n",
       "          0.9078,  0.8848,  0.6061, -0.7711],\n",
       "        [ 0.9999, -0.9295,  0.8276,  0.6763, -0.7959,  0.9970,  0.7021,  0.8766,\n",
       "         -0.6100,  0.6472,  0.1232,  0.9999,  0.9681,  0.9991,  0.9778,  0.8574,\n",
       "          0.9352,  0.0182,  0.9674,  0.7173,  0.6034,  0.8075,  0.9029,  0.9848,\n",
       "          0.9704,  0.8435,  0.8102, -0.8373],\n",
       "        [ 0.9998, -0.9328,  0.6473,  0.6666, -0.7473,  0.9888,  0.6628,  0.9044,\n",
       "         -0.6107,  0.1179,  0.4286,  0.9999,  0.9193,  0.9993,  0.9399,  0.7917,\n",
       "          0.7279,  0.5126,  0.9846,  0.7432,  0.6282,  0.3839,  0.7915,  0.9339,\n",
       "          0.8617,  0.6998,  0.7090, -0.7574],\n",
       "        [ 1.0000, -0.9800,  0.1618, -0.2572, -0.5314,  0.9160, -0.2219, -0.1677,\n",
       "          0.2166, -0.6633,  0.8263,  1.0000,  0.9656,  0.9997, -0.3167, -0.4855,\n",
       "         -0.7969, -0.7502,  0.9922,  0.7310,  0.5002, -0.1124,  0.4768,  0.3598,\n",
       "         -0.6229,  0.4852, -0.2596, -0.5064],\n",
       "        [ 1.0000, -0.9839,  0.0582, -0.3284, -0.5574,  0.8895, -0.3445, -0.3292,\n",
       "          0.3104, -0.7296,  0.8615,  1.0000,  0.9656,  0.9998, -0.5371, -0.6064,\n",
       "         -0.8804, -0.7697,  0.9945,  0.7582,  0.5163, -0.2875,  0.4001,  0.1418,\n",
       "         -0.7730,  0.4701, -0.3377, -0.4991],\n",
       "        [ 1.0000, -0.9853,  0.0379, -0.3342, -0.5776,  0.8866, -0.3728, -0.3760,\n",
       "          0.3342, -0.7394,  0.8697,  1.0000,  0.9660,  0.9999, -0.5843, -0.6321,\n",
       "         -0.8966, -0.7709,  0.9953,  0.7744,  0.5342, -0.3493,  0.3845,  0.0780,\n",
       "         -0.8032,  0.4766, -0.3446, -0.5172],\n",
       "        [ 1.0000, -0.9632,  0.9099,  0.7872, -0.9052,  0.9992,  0.8704,  0.9815,\n",
       "         -0.7309,  0.7557,  0.1495,  1.0000,  0.9898,  0.9998,  0.9960,  0.9372,\n",
       "          0.9820,  0.3135,  0.9866,  0.8105,  0.6643,  0.8854,  0.9596,  0.9955,\n",
       "          0.9934,  0.9469,  0.8858, -0.9078],\n",
       "        [ 0.9994, -0.9062,  0.0763, -0.0693, -0.5284,  0.7816, -0.2447, -0.3400,\n",
       "          0.1726, -0.4061,  0.6672,  0.9997,  0.8225,  0.9973, -0.3839, -0.2977,\n",
       "         -0.6747, -0.4350,  0.9691,  0.6852,  0.4913, -0.3999,  0.2614,  0.0437,\n",
       "         -0.5545,  0.4016, -0.0405, -0.5186]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
