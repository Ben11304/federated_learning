{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thống kê nhãn attack:\n",
      "1 6095\n",
      "0 931\n",
      "thống kê nhãn category:\n",
      "0 2994\n",
      "1 931\n",
      "3 1109\n",
      "2 1992\n",
      "thống kê nhãn subcategory :\n",
      "6 1000\n",
      "7 1000\n",
      "3 931\n",
      "2 995\n",
      "4 992\n",
      "5 1000\n",
      "1 994\n",
      "0 114\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_work import processed\n",
    "from data_work import analyse_dataset\n",
    "df=pd.read_csv(\"/Users/mac/Dev/data/dta_IoT/new2test.csv\")\n",
    "#delete all null columns\n",
    "id=[16,17,21,22,23,24]\n",
    "col=df.columns\n",
    "for idx in id:\n",
    "    df=df.drop(col[idx],axis=1)\n",
    "data=processed(df,\"subcategory \")\n",
    "names=[\"attack\",\"category\",\"subcategory \"]\n",
    "analyse_dataset(data,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 1, 0],\n",
       "        [0, 0, 0,  ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "labels=torch.tensor(data[\"subcategory \"])\n",
    "labels_one_hot = F.one_hot(labels, 8)\n",
    "labels_one_hot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(\"subcategory \",axis=1)\n",
    "X=torch.tensor(X.values)\n",
    "data=torch.cat((X, labels_one_hot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils, torch, time, os, pickle\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class generator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n",
    "    def __init__(self, input_dim=100, output_dim=1, input_size=32, class_num=8):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim + self.class_num, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024,512)\n",
    "            nn.ReLU()\n",
    "            nn.Linear(512 ,self.output_dim)\n",
    "        )\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
    "    # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
    "    def __init__(self, input_dim=1, output_dim=1, input_size=32, class_num=8):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_size = input_size\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim+self.class_num, 512),\n",
    "            nn.ReLU()\n",
    "            nn.Linear(512,1024)\n",
    "            nn.ReLU()\n",
    "            nn.Linear(1024,512)\n",
    "            nn.ReLU\n",
    "            nn.Linear(512, self.output_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        utils.initialize_weights(self)\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CGAN(object):\n",
    "    def __init__(self, args):\n",
    "        # parameters\n",
    "        self.epoch = args.epoch\n",
    "        self.batch_size = args.batch_size\n",
    "        self.save_dir = args.save_dir\n",
    "        self.result_dir = args.result_dir\n",
    "        self.dataset = args.dataset\n",
    "        self.log_dir = args.log_dir\n",
    "        self.gpu_mode = args.gpu_mode\n",
    "        self.model_name = args.gan_type\n",
    "        self.input_size = args.input_size\n",
    "        self.z_dim = 62\n",
    "        self.class_num = args.n_class\n",
    "        self.sample_num = self.class_num ** 2 \n",
    "        # load dataset\n",
    "        self.data_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        #data = self.data_loader.__iter__().__next__()[0]\n",
    "        data=next(iter(self.data_loader))\n",
    "        #option\n",
    "        dim=int(data.shape[1])-8\n",
    "\n",
    "        # networks init\n",
    "        self.G = generator(input_dim=self.z_dim, output_dim=dim, input_size=self.input_size, class_num=self.class_num)\n",
    "        self.D = discriminator(input_dim=dim, output_dim=1, input_size=self.input_size, class_num=self.class_num)\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
    "\n",
    "        self.BCE_loss = nn.BCELoss()\n",
    "\n",
    "        print('---------- Networks architecture -------------')\n",
    "        utils.print_network(self.G)\n",
    "        utils.print_network(self.D)\n",
    "        print('-----------------------------------------------')\n",
    "\n",
    "        # fixed noise & condition\n",
    "        self.sample_z_ = torch.zeros((self.sample_num, self.z_dim)) # z_dim tượng trưng cho noise vector, vector nhiều có kích thuóc dài bằng vector onehotencoded^2 của label \n",
    "        for i in range(self.class_num):\n",
    "            self.sample_z_[i*self.class_num] = torch.rand(1, self.z_dim)#tạo một vector random có kích thuớc 1, z_dim ( chiều dài của vector nhiễu )\n",
    "            for j in range(1, self.class_num):\n",
    "                self.sample_z_[i*self.class_num + j] = self.sample_z_[i*self.class_num]\n",
    "\n",
    "        temp = torch.zeros((self.class_num, 1))\n",
    "        for i in range(self.class_num):\n",
    "            temp[i, 0] = i\n",
    "\n",
    "        temp_y = torch.zeros((self.sample_num, 1))\n",
    "        for i in range(self.class_num):\n",
    "            temp_y[i*self.class_num: (i+1)*self.class_num] = temp\n",
    "\n",
    "        self.sample_y_ = torch.zeros((self.sample_num, self.class_num)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.train_hist = {}\n",
    "        self.train_hist['D_loss'] = []\n",
    "        self.train_hist['G_loss'] = []\n",
    "        self.train_hist['per_epoch_time'] = []\n",
    "        self.train_hist['total_time'] = []\n",
    "\n",
    "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n",
    "\n",
    "        self.D.train()\n",
    "        print('training start!!')\n",
    "        start_time = time.time()\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train()\n",
    "            epoch_start_time = time.time()\n",
    "            for iter, da in enumerate(self.data_loader):\n",
    "                x_=da[:,:28].float()\n",
    "                y_=da[:,-8:].float()\n",
    "                if iter == self.data_loader.dataset.__len__() // self.batch_size:\n",
    "                    break\n",
    "\n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                #y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor), 1)\n",
    "                #y_fill_ = y_vec_.unsqueeze(2).unsqueeze(3).expand(self.batch_size, self.class_num, self.input_size, self.input_size)\n",
    "\n",
    "                # update D network\n",
    "                self.D_optimizer.zero_grad()\n",
    "\n",
    "                D_real = self.D(x_, y_)\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "\n",
    "                G_ = self.G(z_, y_)\n",
    "                D_fake = self.D(G_, y_)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "\n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                self.train_hist['D_loss'].append(D_loss.item())\n",
    "\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "\n",
    "                # update G network\n",
    "                self.G_optimizer.zero_grad()\n",
    "\n",
    "                G_ = self.G(z_, y_)\n",
    "                D_fake = self.D(G_, y_)\n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "                self.train_hist['G_loss'].append(G_loss.item())\n",
    "\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "                if ((iter + 1) % 100) == 0:\n",
    "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
    "                          ((epoch + 1), (iter + 1), self.data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
    "\n",
    "            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
    "            with torch.no_grad():\n",
    "                print(\"OK\")\n",
    "                \n",
    "\n",
    "        self.train_hist['total_time'].append(time.time() - start_time)\n",
    "        print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.train_hist['per_epoch_time']),\n",
    "              self.epoch, self.train_hist['total_time'][0]))\n",
    "        print(\"Training finish!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self,data):\n",
    "        self.epoch = 50\n",
    "        self.batch_size = 32\n",
    "        self.save_dir = '/Users/mac/Dev/source/article/FerderatedLearning/federated_learning/NonIID/model.h5'\n",
    "        self.result_dir = '/Users/mac/Dev/source/article/FerderatedLearning/federated_learning/NonIID/result.txt'\n",
    "        self.dataset = data\n",
    "        self.log_dir = 'logs/'\n",
    "        self.gpu_mode = True\n",
    "        self.gan_type = 'infoGAN'\n",
    "        self.input_size = 32\n",
    "        self.z_dim = 62\n",
    "        self.n_class = 8\n",
    "        self.sample_num = self.n_class ** 2\n",
    "        self.lrG=0.002\n",
    "        self.lrD=0.002\n",
    "        self.beta1=0.9\n",
    "        self.beta2=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5333, 2842,    7,  ...,    0,    1,    0],\n",
      "        [5216, 2725,    7,  ...,    0,    1,    0],\n",
      "        [6306, 3797,    0,  ...,    0,    0,    1],\n",
      "        ...,\n",
      "        [3998, 5464,    0,  ...,    0,    0,    0],\n",
      "        [5798, 3307,    7,  ...,    0,    1,    0],\n",
      "        [5379, 2888,    6,  ...,    0,    1,    0]])\n"
     ]
    }
   ],
   "source": [
    "arg=Args(data)\n",
    "print(arg.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "generator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=70, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=28, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 614940\n",
      "discriminator(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=36, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 40961\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model=CGAN(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!!\n",
      "Epoch: [ 1] [ 100/ 219] D_loss: 0.88499707, G_loss: 1.29847598\n",
      "Epoch: [ 1] [ 200/ 219] D_loss: 0.62361205, G_loss: 1.78231609\n",
      "OK\n",
      "Epoch: [ 2] [ 100/ 219] D_loss: 0.43072447, G_loss: 2.00979185\n",
      "Epoch: [ 2] [ 200/ 219] D_loss: 0.46461743, G_loss: 1.92128348\n",
      "OK\n",
      "Epoch: [ 3] [ 100/ 219] D_loss: 0.59615886, G_loss: 1.53919792\n",
      "Epoch: [ 3] [ 200/ 219] D_loss: 0.67787862, G_loss: 1.46551633\n",
      "OK\n",
      "Epoch: [ 4] [ 100/ 219] D_loss: 0.54020572, G_loss: 2.39436412\n",
      "Epoch: [ 4] [ 200/ 219] D_loss: 0.34877545, G_loss: 2.25819278\n",
      "OK\n",
      "Epoch: [ 5] [ 100/ 219] D_loss: 0.58744091, G_loss: 1.88523638\n",
      "Epoch: [ 5] [ 200/ 219] D_loss: 0.90095377, G_loss: 1.07679880\n",
      "OK\n",
      "Epoch: [ 6] [ 100/ 219] D_loss: 0.77850556, G_loss: 1.76344192\n",
      "Epoch: [ 6] [ 200/ 219] D_loss: 0.64233410, G_loss: 1.83246672\n",
      "OK\n",
      "Epoch: [ 7] [ 100/ 219] D_loss: 0.51161551, G_loss: 2.01502156\n",
      "Epoch: [ 7] [ 200/ 219] D_loss: 0.83974361, G_loss: 1.74139845\n",
      "OK\n",
      "Epoch: [ 8] [ 100/ 219] D_loss: 0.62014532, G_loss: 1.64481616\n",
      "Epoch: [ 8] [ 200/ 219] D_loss: 0.87087274, G_loss: 1.57616389\n",
      "OK\n",
      "Epoch: [ 9] [ 100/ 219] D_loss: 0.40788460, G_loss: 2.34297276\n",
      "Epoch: [ 9] [ 200/ 219] D_loss: 1.01407337, G_loss: 2.01312089\n",
      "OK\n",
      "Epoch: [10] [ 100/ 219] D_loss: 0.54036540, G_loss: 1.83201444\n",
      "Epoch: [10] [ 200/ 219] D_loss: 0.36842549, G_loss: 2.34302402\n",
      "OK\n",
      "Epoch: [11] [ 100/ 219] D_loss: 0.98694652, G_loss: 1.53819346\n",
      "Epoch: [11] [ 200/ 219] D_loss: 0.97804630, G_loss: 1.53346181\n",
      "OK\n",
      "Epoch: [12] [ 100/ 219] D_loss: 0.80695605, G_loss: 1.66571641\n",
      "Epoch: [12] [ 200/ 219] D_loss: 0.59675336, G_loss: 1.71569133\n",
      "OK\n",
      "Epoch: [13] [ 100/ 219] D_loss: 0.98186201, G_loss: 1.01858902\n",
      "Epoch: [13] [ 200/ 219] D_loss: 0.99958444, G_loss: 1.49192870\n",
      "OK\n",
      "Epoch: [14] [ 100/ 219] D_loss: 0.93138999, G_loss: 1.31765831\n",
      "Epoch: [14] [ 200/ 219] D_loss: 1.27944720, G_loss: 1.47551036\n",
      "OK\n",
      "Epoch: [15] [ 100/ 219] D_loss: 0.71178782, G_loss: 1.70508647\n",
      "Epoch: [15] [ 200/ 219] D_loss: 0.87009895, G_loss: 1.07315266\n",
      "OK\n",
      "Epoch: [16] [ 100/ 219] D_loss: 0.84623933, G_loss: 1.35357952\n",
      "Epoch: [16] [ 200/ 219] D_loss: 0.95786428, G_loss: 1.78800178\n",
      "OK\n",
      "Epoch: [17] [ 100/ 219] D_loss: 1.07809651, G_loss: 1.26372504\n",
      "Epoch: [17] [ 200/ 219] D_loss: 0.60848445, G_loss: 1.67249310\n",
      "OK\n",
      "Epoch: [18] [ 100/ 219] D_loss: 0.85895562, G_loss: 2.05974269\n",
      "Epoch: [18] [ 200/ 219] D_loss: 0.85006809, G_loss: 1.31814921\n",
      "OK\n",
      "Epoch: [19] [ 100/ 219] D_loss: 0.85548019, G_loss: 1.40907395\n",
      "Epoch: [19] [ 200/ 219] D_loss: 0.75390172, G_loss: 1.70975709\n",
      "OK\n",
      "Epoch: [20] [ 100/ 219] D_loss: 0.62908924, G_loss: 1.48380899\n",
      "Epoch: [20] [ 200/ 219] D_loss: 0.90778965, G_loss: 1.15076637\n",
      "OK\n",
      "Epoch: [21] [ 100/ 219] D_loss: 0.89860541, G_loss: 1.26293111\n",
      "Epoch: [21] [ 200/ 219] D_loss: 0.72206789, G_loss: 1.40064096\n",
      "OK\n",
      "Epoch: [22] [ 100/ 219] D_loss: 0.70950472, G_loss: 1.99253106\n",
      "Epoch: [22] [ 200/ 219] D_loss: 0.83206475, G_loss: 1.30022430\n",
      "OK\n",
      "Epoch: [23] [ 100/ 219] D_loss: 0.94418675, G_loss: 1.52028489\n",
      "Epoch: [23] [ 200/ 219] D_loss: 0.77461898, G_loss: 1.58655572\n",
      "OK\n",
      "Epoch: [24] [ 100/ 219] D_loss: 0.95182055, G_loss: 1.28382099\n",
      "Epoch: [24] [ 200/ 219] D_loss: 0.85198170, G_loss: 1.22502673\n",
      "OK\n",
      "Epoch: [25] [ 100/ 219] D_loss: 0.93289340, G_loss: 1.51461232\n",
      "Epoch: [25] [ 200/ 219] D_loss: 0.89506781, G_loss: 1.67156386\n",
      "OK\n",
      "Epoch: [26] [ 100/ 219] D_loss: 0.97286510, G_loss: 1.45743251\n",
      "Epoch: [26] [ 200/ 219] D_loss: 0.95137829, G_loss: 1.34557605\n",
      "OK\n",
      "Epoch: [27] [ 100/ 219] D_loss: 0.73053926, G_loss: 1.40762317\n",
      "Epoch: [27] [ 200/ 219] D_loss: 0.56644207, G_loss: 1.44883442\n",
      "OK\n",
      "Epoch: [28] [ 100/ 219] D_loss: 1.07296562, G_loss: 1.10450864\n",
      "Epoch: [28] [ 200/ 219] D_loss: 1.18450999, G_loss: 1.62909365\n",
      "OK\n",
      "Epoch: [29] [ 100/ 219] D_loss: 1.27998352, G_loss: 1.50691414\n",
      "Epoch: [29] [ 200/ 219] D_loss: 0.80256689, G_loss: 1.30454838\n",
      "OK\n",
      "Epoch: [30] [ 100/ 219] D_loss: 0.93489528, G_loss: 1.60620761\n",
      "Epoch: [30] [ 200/ 219] D_loss: 1.01093626, G_loss: 1.71542037\n",
      "OK\n",
      "Epoch: [31] [ 100/ 219] D_loss: 0.86975336, G_loss: 1.24998856\n",
      "Epoch: [31] [ 200/ 219] D_loss: 0.95690596, G_loss: 1.50237095\n",
      "OK\n",
      "Epoch: [32] [ 100/ 219] D_loss: 0.95101923, G_loss: 1.51567400\n",
      "Epoch: [32] [ 200/ 219] D_loss: 0.95963037, G_loss: 1.28847086\n",
      "OK\n",
      "Epoch: [33] [ 100/ 219] D_loss: 1.38017464, G_loss: 1.11971760\n",
      "Epoch: [33] [ 200/ 219] D_loss: 1.07019997, G_loss: 1.88711429\n",
      "OK\n",
      "Epoch: [34] [ 100/ 219] D_loss: 0.87718970, G_loss: 1.79076469\n",
      "Epoch: [34] [ 200/ 219] D_loss: 0.89871097, G_loss: 1.78463817\n",
      "OK\n",
      "Epoch: [35] [ 100/ 219] D_loss: 0.80817223, G_loss: 1.38849556\n",
      "Epoch: [35] [ 200/ 219] D_loss: 0.87068570, G_loss: 1.46431398\n",
      "OK\n",
      "Epoch: [36] [ 100/ 219] D_loss: 1.01547444, G_loss: 1.31888103\n",
      "Epoch: [36] [ 200/ 219] D_loss: 1.06285131, G_loss: 1.34879160\n",
      "OK\n",
      "Epoch: [37] [ 100/ 219] D_loss: 0.84644407, G_loss: 1.78110898\n",
      "Epoch: [37] [ 200/ 219] D_loss: 1.06381750, G_loss: 1.59225810\n",
      "OK\n",
      "Epoch: [38] [ 100/ 219] D_loss: 0.64931422, G_loss: 1.74993730\n",
      "Epoch: [38] [ 200/ 219] D_loss: 0.95248032, G_loss: 2.07264209\n",
      "OK\n",
      "Epoch: [39] [ 100/ 219] D_loss: 0.96219867, G_loss: 1.65659964\n",
      "Epoch: [39] [ 200/ 219] D_loss: 0.90679944, G_loss: 1.72963929\n",
      "OK\n",
      "Epoch: [40] [ 100/ 219] D_loss: 0.65545738, G_loss: 1.60789728\n",
      "Epoch: [40] [ 200/ 219] D_loss: 0.91566336, G_loss: 2.07166719\n",
      "OK\n",
      "Epoch: [41] [ 100/ 219] D_loss: 0.80345255, G_loss: 1.96901762\n",
      "Epoch: [41] [ 200/ 219] D_loss: 0.72782624, G_loss: 2.28775668\n",
      "OK\n",
      "Epoch: [42] [ 100/ 219] D_loss: 0.93912017, G_loss: 1.70880747\n",
      "Epoch: [42] [ 200/ 219] D_loss: 1.31978154, G_loss: 1.62589896\n",
      "OK\n",
      "Epoch: [43] [ 100/ 219] D_loss: 0.69553775, G_loss: 2.01640463\n",
      "Epoch: [43] [ 200/ 219] D_loss: 0.97703981, G_loss: 1.36768842\n",
      "OK\n",
      "Epoch: [44] [ 100/ 219] D_loss: 0.79444313, G_loss: 1.63566232\n",
      "Epoch: [44] [ 200/ 219] D_loss: 0.92273086, G_loss: 2.02567649\n",
      "OK\n",
      "Epoch: [45] [ 100/ 219] D_loss: 0.70693243, G_loss: 1.83240056\n",
      "Epoch: [45] [ 200/ 219] D_loss: 0.51902610, G_loss: 2.06950259\n",
      "OK\n",
      "Epoch: [46] [ 100/ 219] D_loss: 0.86043119, G_loss: 1.55355382\n",
      "Epoch: [46] [ 200/ 219] D_loss: 0.67224145, G_loss: 1.67201757\n",
      "OK\n",
      "Epoch: [47] [ 100/ 219] D_loss: 0.87649214, G_loss: 1.52647674\n",
      "Epoch: [47] [ 200/ 219] D_loss: 0.95887786, G_loss: 2.36702323\n",
      "OK\n",
      "Epoch: [48] [ 100/ 219] D_loss: 0.62519360, G_loss: 2.34104872\n",
      "Epoch: [48] [ 200/ 219] D_loss: 0.68520063, G_loss: 1.79352963\n",
      "OK\n",
      "Epoch: [49] [ 100/ 219] D_loss: 0.76305699, G_loss: 1.89722991\n",
      "Epoch: [49] [ 200/ 219] D_loss: 0.86640269, G_loss: 1.92773342\n",
      "OK\n",
      "Epoch: [50] [ 100/ 219] D_loss: 0.66332519, G_loss: 2.00939727\n",
      "Epoch: [50] [ 200/ 219] D_loss: 0.77584618, G_loss: 1.64950025\n",
      "OK\n",
      "Avg one epoch time: 2.26, total 50 epochs time: 112.93\n",
      "Training finish!\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=torch.tensor([1,2,3,4,5,6,7,0])\n",
    "y=F.one_hot(y, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len=y.shape[0]\n",
    "len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0j/2h4f0bj12r775fg_s2v4hpqh0000gn/T/ipykernel_27098/2598516341.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  yin=torch.tensor(yin)\n"
     ]
    }
   ],
   "source": [
    "z= torch.rand(len,62)\n",
    "yin=torch.tensor(yin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=torch.cat([z,y],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fake=model.G(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0996e+02, -1.2504e+02,  7.6761e-01,  2.5407e+00, -7.3504e-01,\n",
       "         -1.0051e+02, -2.2982e+00,  5.2797e-01,  2.2641e+00, -1.1278e+00,\n",
       "         -7.8942e+00, -1.0998e+02, -1.4136e+01, -5.1857e+01, -5.3497e+01,\n",
       "         -1.5120e+01, -4.0590e+01, -8.3259e+00, -3.4016e+01, -1.4989e+00,\n",
       "         -6.0830e+00,  8.5784e+00, -1.8214e+00,  6.8878e+01, -9.6606e+00,\n",
       "         -4.3562e+00,  1.1937e+00, -3.4673e+00],\n",
       "        [ 5.3926e+01,  8.4354e+01,  2.3195e-01,  1.1873e+00,  2.4098e+00,\n",
       "         -4.3801e+01, -1.5839e-01, -5.9253e+00,  2.1230e-01, -4.4225e+00,\n",
       "         -2.3346e+00,  7.0126e+01, -1.0444e+01, -2.0543e+01, -9.5574e+00,\n",
       "          9.6565e-01, -6.0391e-01, -6.1603e+00, -6.8346e+00, -2.7305e-01,\n",
       "          1.6098e+00,  1.2959e+00, -4.5213e-01,  2.3616e+01, -1.1262e+00,\n",
       "          3.6198e-01, -3.3272e+00,  1.6809e+00],\n",
       "        [ 8.6594e+01, -1.5694e+00, -3.1943e+00, -4.0194e-01,  1.7311e+00,\n",
       "         -1.0148e+02, -1.3796e-01, -4.8547e+00,  2.9745e+00, -9.5748e+00,\n",
       "         -2.8444e+00, -2.8045e+00,  5.4738e+01,  3.7646e+01, -2.3413e+01,\n",
       "         -1.0910e+01, -3.1471e+01, -1.4417e+01, -2.2760e+01,  3.5773e+00,\n",
       "          4.5918e+00,  1.9545e+00,  1.5090e+00, -2.2075e+01,  3.2990e+00,\n",
       "          2.1888e+00, -9.2837e+00, -3.8148e+00],\n",
       "        [ 1.9384e+02,  7.6342e+01, -4.2919e+00,  6.3265e-02,  4.0322e+00,\n",
       "         -1.3657e+02, -3.2859e+00, -2.4265e+00, -1.1268e+00, -1.0553e+01,\n",
       "         -1.9278e+00,  5.6006e+01, -7.3940e+00,  6.6329e+01,  6.1569e+01,\n",
       "          4.3310e+01,  1.0103e+02, -1.5014e+01,  7.7705e+01,  6.0035e-01,\n",
       "          3.6794e+00, -5.6920e+00,  3.1309e+00, -4.6537e+01,  2.0120e+01,\n",
       "          1.2419e+00, -8.7413e+00, -5.0482e-01],\n",
       "        [ 4.6342e+00, -1.4475e+01,  2.8235e+00,  8.6131e-01,  7.8651e-01,\n",
       "         -2.7233e+01,  4.0693e-01,  2.5162e+00,  1.2286e+00,  5.3962e-01,\n",
       "         -3.2184e+00, -1.0549e+01, -1.9715e+00, -4.2729e+01, -3.6324e+01,\n",
       "         -1.2927e+01, -3.5659e+01, -7.1645e+00, -3.0243e+01, -3.8813e+00,\n",
       "         -9.9923e-01,  5.2553e+00, -1.0183e+00,  5.9236e+01, -5.1258e+00,\n",
       "          1.3185e+00, -3.3565e-01,  4.7357e-02],\n",
       "        [ 3.2034e+01,  7.2362e+01,  9.8850e-01,  3.2454e+00,  9.4025e-01,\n",
       "         -4.7581e+00, -3.7397e+00, -3.7340e+00,  2.3858e+00,  8.9762e+00,\n",
       "         -1.8374e-03,  6.6203e+01, -1.5179e+01,  3.8200e+01,  1.9085e+01,\n",
       "          3.1823e+01,  3.4147e+01, -1.4469e+01,  3.3440e+01,  1.7399e+00,\n",
       "          3.6451e+00,  3.7249e+00,  1.6480e+00, -1.4381e+01,  1.0692e+01,\n",
       "          1.1669e+01, -5.0173e+00,  3.0609e-01],\n",
       "        [ 4.4882e+01,  6.9527e+01, -1.9079e+00,  3.2736e+00,  1.0594e+00,\n",
       "         -2.6763e+01,  1.4896e+00, -9.8650e+00, -7.5271e+00,  1.9571e+01,\n",
       "         -6.6944e+00,  6.8190e+01, -1.8036e+01,  4.0632e+01,  2.3382e+01,\n",
       "         -8.1247e+00,  2.3621e+01,  4.5912e+01,  1.4236e+01, -4.5587e-01,\n",
       "          4.6506e+00,  1.8051e+01,  1.0367e+01, -5.0888e+00,  4.9307e+01,\n",
       "          4.6678e+01, -1.3648e+01, -5.7185e+00],\n",
       "        [ 5.4733e+01,  1.0359e+02,  1.6538e+00, -1.0208e-01,  2.4649e+00,\n",
       "         -2.8199e+01,  2.4960e+00, -1.0041e+01, -1.2838e+00, -3.8353e+00,\n",
       "         -2.7933e+00,  8.9591e+01,  1.3725e+00, -3.3226e+01, -3.2869e+01,\n",
       "         -1.1110e+01, -3.2015e+01, -4.6518e+00, -3.7083e+01, -4.9282e-01,\n",
       "          3.3271e+00,  5.2930e+00, -6.1563e-01,  3.6922e+01,  4.9456e+00,\n",
       "          5.2791e+00, -3.1476e+00,  3.8423e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
